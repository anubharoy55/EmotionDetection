{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48f0cb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2feba88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"fer2013.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0086f0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35887it [02:14, 267.08it/s]\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "\n",
    "for i, j, k in tqdm(zip(data[\"emotion\"], data[\"pixels\"], data[\"Usage\"])):\n",
    "    pixel = []\n",
    "    pixels = j.split(' ')\n",
    "    for m in pixels:\n",
    "        value = float(m)\n",
    "        pixel.append(value)\n",
    "    pixel = np.array(pixel)\n",
    "    #print(pixel.shape)\n",
    "    image = pixel.reshape(48, 48)\n",
    "    #print(image.shape)\n",
    "    \n",
    "    if k == \"Training\":\n",
    "        if not os.path.exists(\"train\"):\n",
    "            os.mkdir(\"train\")\n",
    "        if i == 0:\n",
    "            if not os.path.exists(\"train/Angry\"):\n",
    "                os.mkdir(\"train/Angry\")\n",
    "                path = \"train/Angry/\" + str(count) + \".jpg\"\n",
    "                cv2.imwrite(path , image)\n",
    "                count += 1\n",
    "            else:\n",
    "                path = \"train/Angry/\" + str(count) + \".jpg\"\n",
    "                cv2.imwrite(path , image)\n",
    "                count += 1\n",
    "        \n",
    "        elif i == 1:\n",
    "            if not os.path.exists(\"train/Disgust\"):\n",
    "                os.mkdir(\"train/Disgust\")\n",
    "                path = \"train/Disgust/\" + str(count) + \".jpg\"\n",
    "                cv2.imwrite(path , image)\n",
    "                count += 1\n",
    "            else:\n",
    "                path = \"train/Disgust/\" + str(count) + \".jpg\"\n",
    "                cv2.imwrite(path , image)\n",
    "                count += 1\n",
    "        \n",
    "        elif i == 2:\n",
    "            if not os.path.exists(\"train/Fear\"):\n",
    "                os.mkdir(\"train/Fear\")\n",
    "                path = \"train/Fear/\" + str(count) + \".jpg\"\n",
    "                cv2.imwrite(path , image)\n",
    "                count += 1\n",
    "            else:\n",
    "                path = \"train/Fear/\" + str(count) + \".jpg\"\n",
    "                cv2.imwrite(path , image)\n",
    "                count += 1\n",
    "                \n",
    "        elif i == 3:\n",
    "            if not os.path.exists(\"train/Happy\"):\n",
    "                os.mkdir(\"train/Happy\")\n",
    "                path = \"train/Happy/\" + str(count) + \".jpg\"\n",
    "                cv2.imwrite(path , image)\n",
    "                count += 1\n",
    "            else:\n",
    "                path = \"train/Happy/\" + str(count) + \".jpg\"\n",
    "                cv2.imwrite(path , image)\n",
    "                count += 1\n",
    "                \n",
    "        elif i == 4:\n",
    "            if not os.path.exists(\"train/Sad\"):\n",
    "                os.mkdir(\"train/Sad\")\n",
    "                path = \"train/Sad/\" + str(count) + \".jpg\"\n",
    "                cv2.imwrite(path , image)\n",
    "                count += 1\n",
    "            else:\n",
    "                path = \"train/Sad/\" + str(count) + \".jpg\"\n",
    "                cv2.imwrite(path , image)\n",
    "                count += 1\n",
    "                \n",
    "        elif i == 5:\n",
    "            if not os.path.exists(\"train/Surprise\"):\n",
    "                os.mkdir(\"train/Surprise\")\n",
    "                path = \"train/Surprise/\" + str(count) + \".jpg\"\n",
    "                cv2.imwrite(path , image)\n",
    "                count += 1\n",
    "            else:\n",
    "                path = \"train/Surprise/\" + str(count) + \".jpg\"\n",
    "                cv2.imwrite(path , image)\n",
    "                count += 1\n",
    "                \n",
    "        elif i == 6:\n",
    "            if not os.path.exists(\"train/Neutral\"):\n",
    "                os.mkdir(\"train/Neutral\")\n",
    "                path = \"train/Neutral/\" + str(count) + \".jpg\"\n",
    "                cv2.imwrite(path , image)\n",
    "                count += 1\n",
    "            else:\n",
    "                path = \"train/Neutral/\" + str(count) + \".jpg\"\n",
    "                cv2.imwrite(path , image)\n",
    "                count += 1\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        if not os.path.exists(\"validation\"):\n",
    "            os.mkdir(\"validation\")\n",
    "        \n",
    "        if i == 0:\n",
    "            if not os.path.exists(\"validation/Angry\"):\n",
    "                os.mkdir(\"validation/Angry\")\n",
    "                path = \"validation/Angry/\" + str(count) + \".jpg\"\n",
    "                cv2.imwrite(path , image)\n",
    "                count += 1\n",
    "            else:\n",
    "                path = \"validation/Angry/\" + str(count) + \".jpg\"\n",
    "                cv2.imwrite(path , image)\n",
    "                count += 1\n",
    "        \n",
    "        elif i == 1:\n",
    "            if not os.path.exists(\"validation/Disgust\"):\n",
    "                os.mkdir(\"validation/Disgust\")\n",
    "                path = \"validation/Disgust/\" + str(count) + \".jpg\"\n",
    "                cv2.imwrite(path , image)\n",
    "                count += 1\n",
    "            else:\n",
    "                path = \"validation/Disgust/\" + str(count) + \".jpg\"\n",
    "                cv2.imwrite(path , image)\n",
    "                count += 1\n",
    "        \n",
    "        elif i == 2:\n",
    "            if not os.path.exists(\"validation/Fear\"):\n",
    "                os.mkdir(\"validation/Fear\")\n",
    "                path = \"validation/Fear/\" + str(count) + \".jpg\"\n",
    "                cv2.imwrite(path , image)\n",
    "                count += 1\n",
    "            else:\n",
    "                path = \"validation/Fear/\" + str(count) + \".jpg\"\n",
    "                cv2.imwrite(path , image)\n",
    "                count += 1\n",
    "                \n",
    "        elif i == 3:\n",
    "            if not os.path.exists(\"validation/Happy\"):\n",
    "                os.mkdir(\"validation/Happy\")\n",
    "                path = \"validation/Happy/\" + str(count) + \".jpg\"\n",
    "                cv2.imwrite(path , image)\n",
    "                count += 1\n",
    "            else:\n",
    "                path = \"validation/Happy/\" + str(count) + \".jpg\"\n",
    "                cv2.imwrite(path , image)\n",
    "                count += 1\n",
    "                \n",
    "        elif i == 4:\n",
    "            if not os.path.exists(\"validation/Sad\"):\n",
    "                os.mkdir(\"validation/Sad\")\n",
    "                path = \"validation/Sad/\" + str(count) + \".jpg\"\n",
    "                cv2.imwrite(path , image)\n",
    "                count += 1\n",
    "            else:\n",
    "                path = \"validation/Sad/\" + str(count) + \".jpg\"\n",
    "                cv2.imwrite(path , image)\n",
    "                count += 1\n",
    "                \n",
    "        elif i == 5:\n",
    "            if not os.path.exists(\"validation/Surprise\"):\n",
    "                os.mkdir(\"validation/Surprise\")\n",
    "                path = \"validation/Surprise/\" + str(count) + \".jpg\"\n",
    "                cv2.imwrite(path , image)\n",
    "                count += 1\n",
    "            else:\n",
    "                path = \"validation/Surprise/\" + str(count) + \".jpg\"\n",
    "                cv2.imwrite(path , image)\n",
    "                count += 1\n",
    "                \n",
    "        elif i == 6:\n",
    "            if not os.path.exists(\"validation/Neutral\"):\n",
    "                os.mkdir(\"validation/Neutral\")\n",
    "                path = \"validation/Neutral/\" + str(count) + \".jpg\"\n",
    "                cv2.imwrite(path , image)\n",
    "                count += 1\n",
    "            else:\n",
    "                path = \"validation/Neutral/\" + str(count) + \".jpg\"\n",
    "                cv2.imwrite(path , image)\n",
    "                count += 1\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7abce22d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3995, 436, 4097, 7215, 4965, 4830, 3171]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_counts = []\n",
    "train_dir= 'C:/Users/Anubha/Documents/SignLanguageDetection/train'\n",
    "classes=[]\n",
    "import os\n",
    " \n",
    "for folder in os.listdir(train_dir):\n",
    "    classes.append(folder)\n",
    "    class_path = train_dir + '/' +folder + '/'\n",
    "    list_train = []\n",
    "    count = 0\n",
    "    for file in os.listdir(class_path):\n",
    "        count +=1\n",
    "    \n",
    "    train_counts.append(count)\n",
    "    \n",
    "train_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00b25e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Counts')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(classes, train_counts, width=0.5)\n",
    "plt.title(\"Bar Graph of Train Data\")\n",
    "plt.xlabel(\"Classes\")\n",
    "plt.ylabel(\"Counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f8efec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(classes, train_counts)\n",
    "plt.plot(classes, train_counts, '-o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6192c75",
   "metadata": {},
   "source": [
    "# The above diagram shows that the data is balanced but one class i.e. Disgust is not at par, so we would remove that class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a87d0cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.remove('train/Disgust') \n",
    "#os.remove('validation/Disgust') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b73ff336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, BatchNormalization, Dense, Flatten, Activation\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "#%pip install pydot\n",
    "#%pip install graphviz\n",
    "import pydot\n",
    "import graphviz\n",
    "import os\n",
    "\n",
    "num_classes = 6\n",
    "\n",
    "Img_Height = 48\n",
    "Img_width = 48\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dir = \"train\"\n",
    "validation_dir = \"validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a29e5530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28273 images belonging to 6 classes.\n",
      "Found 7067 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=60,\n",
    "                                   shear_range=0.5,\n",
    "                                   zoom_range=0.5,\n",
    "                                   width_shift_range=0.5,\n",
    "                                   height_shift_range=0.5,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    color_mode='grayscale',\n",
    "                                                    target_size=(Img_Height, Img_width),\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=True)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_dir,\n",
    "                                                              color_mode='grayscale',\n",
    "                                                              target_size=(Img_Height, Img_width),\n",
    "                                                              batch_size=batch_size,\n",
    "                                                              class_mode='categorical',\n",
    "                                                              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc502211",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Block-1: The First Convolutional Block\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', \n",
    "                 kernel_initializer='he_normal',\n",
    "                 activation=\"relu\", \n",
    "                 input_shape=(Img_Height, Img_width, 1), \n",
    "                 name=\"Conv1\"))\n",
    "\n",
    "model.add(BatchNormalization(name=\"Batch_Norm1\"))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', \n",
    "                 kernel_initializer='he_normal', \n",
    "                 activation=\"relu\", name=\"Conv2\"))\n",
    "\n",
    "model.add(BatchNormalization(name=\"Batch_Norm2\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), name=\"Maxpool1\"))\n",
    "model.add(Dropout(0.2, name=\"Dropout1\"))\n",
    "\n",
    "# Block-2: The Second Convolutional Block\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', \n",
    "                 kernel_initializer='he_normal',\n",
    "                 activation=\"relu\", name=\"Conv3\"))\n",
    "\n",
    "model.add(BatchNormalization(name=\"Batch_Norm3\"))\n",
    "\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding='same',\n",
    "                 kernel_initializer='he_normal', \n",
    "                 activation=\"relu\", name=\"Conv4\"))\n",
    "\n",
    "model.add(BatchNormalization(name=\"Batch_Norm4\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), name=\"Maxpool2\"))\n",
    "model.add(Dropout(0.2, name=\"Dropout2\"))\n",
    "\n",
    "# Block-3: The Third Convolutional Block\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', \n",
    "                 kernel_initializer='he_normal', \n",
    "                 activation=\"relu\", name=\"Conv5\"))\n",
    "\n",
    "model.add(BatchNormalization(name=\"Batch_Norm5\"))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', \n",
    "                 kernel_initializer='he_normal',\n",
    "                 activation=\"relu\", name=\"Conv6\"))\n",
    "\n",
    "model.add(BatchNormalization(name=\"Batch_Norm6\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), name=\"Maxpool3\"))\n",
    "model.add(Dropout(0.2, name=\"Dropout3\"))\n",
    "\n",
    "# Block-4: The Fully Connected Block\n",
    "\n",
    "model.add(Flatten(name=\"Flatten\"))\n",
    "model.add(Dense(64, activation=\"relu\", kernel_initializer='he_normal', name=\"Dense\"))\n",
    "model.add(BatchNormalization(name=\"Batch_Norm7\"))\n",
    "model.add(Dropout(0.5, name=\"Dropout4\"))\n",
    "\n",
    "# Block-5: The Output Block\n",
    "\n",
    "model.add(Dense(num_classes, activation=\"softmax\", kernel_initializer='he_normal', name = \"Output\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9c805d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"emotions.h5\", monitor='accuracy', verbose=1,\n",
    "                              save_best_only=True, mode='auto', period=1)\n",
    "\n",
    "reduce = ReduceLROnPlateau(monitor='accuracy', factor=0.2, patience=10, \n",
    "                           min_lr=0.0001, verbose = 1)\n",
    "\n",
    "logdir='logs'\n",
    "tensorboard_Visualization = TensorBoard(log_dir=logdir, histogram_freq=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "177dba68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 2.1358 - accuracy: 0.1941\n",
      "Epoch 1: accuracy improved from -inf to 0.19406, saving model to emotions.h5\n",
      "443/443 [==============================] - 243s 544ms/step - loss: 2.1358 - accuracy: 0.1941 - val_loss: 1.7578 - val_accuracy: 0.2483 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.8476 - accuracy: 0.2267\n",
      "Epoch 2: accuracy improved from 0.19406 to 0.22675, saving model to emotions.h5\n",
      "443/443 [==============================] - 206s 464ms/step - loss: 1.8476 - accuracy: 0.2267 - val_loss: 1.7272 - val_accuracy: 0.2557 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.7808 - accuracy: 0.2441\n",
      "Epoch 3: accuracy improved from 0.22675 to 0.24407, saving model to emotions.h5\n",
      "443/443 [==============================] - 187s 422ms/step - loss: 1.7808 - accuracy: 0.2441 - val_loss: 1.7276 - val_accuracy: 0.2602 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.7575 - accuracy: 0.2453\n",
      "Epoch 4: accuracy improved from 0.24407 to 0.24532, saving model to emotions.h5\n",
      "443/443 [==============================] - 187s 422ms/step - loss: 1.7575 - accuracy: 0.2453 - val_loss: 1.7288 - val_accuracy: 0.2812 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.7464 - accuracy: 0.2535\n",
      "Epoch 5: accuracy improved from 0.24532 to 0.25346, saving model to emotions.h5\n",
      "443/443 [==============================] - 202s 457ms/step - loss: 1.7464 - accuracy: 0.2535 - val_loss: 1.7117 - val_accuracy: 0.2761 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.7416 - accuracy: 0.2578\n",
      "Epoch 6: accuracy improved from 0.25346 to 0.25775, saving model to emotions.h5\n",
      "443/443 [==============================] - 259s 584ms/step - loss: 1.7416 - accuracy: 0.2578 - val_loss: 1.7279 - val_accuracy: 0.2636 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.7393 - accuracy: 0.2563\n",
      "Epoch 7: accuracy did not improve from 0.25775\n",
      "443/443 [==============================] - 221s 500ms/step - loss: 1.7393 - accuracy: 0.2563 - val_loss: 1.7357 - val_accuracy: 0.2557 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.7372 - accuracy: 0.2615\n",
      "Epoch 8: accuracy improved from 0.25775 to 0.26149, saving model to emotions.h5\n",
      "443/443 [==============================] - 236s 533ms/step - loss: 1.7372 - accuracy: 0.2615 - val_loss: 1.7163 - val_accuracy: 0.2597 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.7346 - accuracy: 0.2555\n",
      "Epoch 9: accuracy did not improve from 0.26149\n",
      "443/443 [==============================] - 212s 479ms/step - loss: 1.7346 - accuracy: 0.2555 - val_loss: 1.7158 - val_accuracy: 0.2585 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.7384 - accuracy: 0.2553\n",
      "Epoch 10: accuracy did not improve from 0.26149\n",
      "443/443 [==============================] - 191s 431ms/step - loss: 1.7384 - accuracy: 0.2553 - val_loss: 1.7177 - val_accuracy: 0.2528 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.7401 - accuracy: 0.2551\n",
      "Epoch 11: accuracy did not improve from 0.26149\n",
      "443/443 [==============================] - 196s 442ms/step - loss: 1.7401 - accuracy: 0.2551 - val_loss: 1.7705 - val_accuracy: 0.2460 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.7373 - accuracy: 0.2527\n",
      "Epoch 12: accuracy did not improve from 0.26149\n",
      "443/443 [==============================] - 195s 439ms/step - loss: 1.7373 - accuracy: 0.2527 - val_loss: 1.7318 - val_accuracy: 0.2375 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.7313 - accuracy: 0.2597\n",
      "Epoch 13: accuracy did not improve from 0.26149\n",
      "443/443 [==============================] - 191s 431ms/step - loss: 1.7313 - accuracy: 0.2597 - val_loss: 1.7030 - val_accuracy: 0.2744 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.7270 - accuracy: 0.2676\n",
      "Epoch 14: accuracy improved from 0.26149 to 0.26764, saving model to emotions.h5\n",
      "443/443 [==============================] - 199s 449ms/step - loss: 1.7270 - accuracy: 0.2676 - val_loss: 1.7599 - val_accuracy: 0.2614 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.7218 - accuracy: 0.2681\n",
      "Epoch 15: accuracy improved from 0.26764 to 0.26806, saving model to emotions.h5\n",
      "443/443 [==============================] - 199s 448ms/step - loss: 1.7218 - accuracy: 0.2681 - val_loss: 1.6921 - val_accuracy: 0.2830 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.7137 - accuracy: 0.2773\n",
      "Epoch 16: accuracy improved from 0.26806 to 0.27730, saving model to emotions.h5\n",
      "443/443 [==============================] - 193s 437ms/step - loss: 1.7137 - accuracy: 0.2773 - val_loss: 1.6965 - val_accuracy: 0.2659 - lr: 0.0010\n",
      "Epoch 17/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.6970 - accuracy: 0.2811\n",
      "Epoch 17: accuracy improved from 0.27730 to 0.28111, saving model to emotions.h5\n",
      "443/443 [==============================] - 193s 436ms/step - loss: 1.6970 - accuracy: 0.2811 - val_loss: 1.7825 - val_accuracy: 0.2585 - lr: 0.0010\n",
      "Epoch 18/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.6928 - accuracy: 0.2787\n",
      "Epoch 18: accuracy did not improve from 0.28111\n",
      "443/443 [==============================] - 191s 431ms/step - loss: 1.6928 - accuracy: 0.2787 - val_loss: 1.7304 - val_accuracy: 0.3023 - lr: 0.0010\n",
      "Epoch 19/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.6787 - accuracy: 0.2927\n",
      "Epoch 19: accuracy improved from 0.28111 to 0.29268, saving model to emotions.h5\n",
      "443/443 [==============================] - 174s 393ms/step - loss: 1.6787 - accuracy: 0.2927 - val_loss: 1.6046 - val_accuracy: 0.3250 - lr: 0.0010\n",
      "Epoch 20/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.6690 - accuracy: 0.2988\n",
      "Epoch 20: accuracy improved from 0.29268 to 0.29878, saving model to emotions.h5\n",
      "443/443 [==============================] - 174s 392ms/step - loss: 1.6690 - accuracy: 0.2988 - val_loss: 1.5824 - val_accuracy: 0.3432 - lr: 0.0010\n",
      "Epoch 21/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.6595 - accuracy: 0.3049\n",
      "Epoch 21: accuracy improved from 0.29878 to 0.30488, saving model to emotions.h5\n",
      "443/443 [==============================] - 174s 393ms/step - loss: 1.6595 - accuracy: 0.3049 - val_loss: 1.6823 - val_accuracy: 0.3261 - lr: 0.0010\n",
      "Epoch 22/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.6372 - accuracy: 0.3124\n",
      "Epoch 22: accuracy improved from 0.30488 to 0.31243, saving model to emotions.h5\n",
      "443/443 [==============================] - 173s 390ms/step - loss: 1.6372 - accuracy: 0.3124 - val_loss: 1.5315 - val_accuracy: 0.3818 - lr: 0.0010\n",
      "Epoch 23/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.6212 - accuracy: 0.3229\n",
      "Epoch 23: accuracy improved from 0.31243 to 0.32287, saving model to emotions.h5\n",
      "443/443 [==============================] - 176s 397ms/step - loss: 1.6212 - accuracy: 0.3229 - val_loss: 1.4611 - val_accuracy: 0.4227 - lr: 0.0010\n",
      "Epoch 24/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.6094 - accuracy: 0.3376\n",
      "Epoch 24: accuracy improved from 0.32287 to 0.33762, saving model to emotions.h5\n",
      "443/443 [==============================] - 174s 394ms/step - loss: 1.6094 - accuracy: 0.3376 - val_loss: 1.4649 - val_accuracy: 0.4278 - lr: 0.0010\n",
      "Epoch 25/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.5913 - accuracy: 0.3459\n",
      "Epoch 25: accuracy improved from 0.33762 to 0.34594, saving model to emotions.h5\n",
      "443/443 [==============================] - 176s 396ms/step - loss: 1.5913 - accuracy: 0.3459 - val_loss: 1.5587 - val_accuracy: 0.4131 - lr: 0.0010\n",
      "Epoch 26/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.5839 - accuracy: 0.3519\n",
      "Epoch 26: accuracy improved from 0.34594 to 0.35188, saving model to emotions.h5\n",
      "443/443 [==============================] - 174s 393ms/step - loss: 1.5839 - accuracy: 0.3519 - val_loss: 1.4297 - val_accuracy: 0.4375 - lr: 0.0010\n",
      "Epoch 27/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.5592 - accuracy: 0.3634\n",
      "Epoch 27: accuracy improved from 0.35188 to 0.36343, saving model to emotions.h5\n",
      "443/443 [==============================] - 175s 396ms/step - loss: 1.5592 - accuracy: 0.3634 - val_loss: 1.3369 - val_accuracy: 0.4750 - lr: 0.0010\n",
      "Epoch 28/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.5679 - accuracy: 0.3620\n",
      "Epoch 28: accuracy did not improve from 0.36343\n",
      "443/443 [==============================] - 175s 396ms/step - loss: 1.5679 - accuracy: 0.3620 - val_loss: 1.4169 - val_accuracy: 0.4511 - lr: 0.0010\n",
      "Epoch 29/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.5389 - accuracy: 0.3780\n",
      "Epoch 29: accuracy improved from 0.36343 to 0.37796, saving model to emotions.h5\n",
      "443/443 [==============================] - 176s 397ms/step - loss: 1.5389 - accuracy: 0.3780 - val_loss: 1.3100 - val_accuracy: 0.4830 - lr: 0.0010\n",
      "Epoch 30/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.5204 - accuracy: 0.3868\n",
      "Epoch 30: accuracy improved from 0.37796 to 0.38678, saving model to emotions.h5\n",
      "443/443 [==============================] - 176s 397ms/step - loss: 1.5204 - accuracy: 0.3868 - val_loss: 1.2949 - val_accuracy: 0.4869 - lr: 0.0010\n",
      "Epoch 31/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.5129 - accuracy: 0.3866\n",
      "Epoch 31: accuracy did not improve from 0.38678\n",
      "443/443 [==============================] - 176s 396ms/step - loss: 1.5129 - accuracy: 0.3866 - val_loss: 1.2750 - val_accuracy: 0.4801 - lr: 0.0010\n",
      "Epoch 32/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.5162 - accuracy: 0.3865\n",
      "Epoch 32: accuracy did not improve from 0.38678\n",
      "443/443 [==============================] - 176s 398ms/step - loss: 1.5162 - accuracy: 0.3865 - val_loss: 1.2789 - val_accuracy: 0.4972 - lr: 0.0010\n",
      "Epoch 33/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.5162 - accuracy: 0.3873\n",
      "Epoch 33: accuracy improved from 0.38678 to 0.38726, saving model to emotions.h5\n",
      "443/443 [==============================] - 176s 397ms/step - loss: 1.5162 - accuracy: 0.3873 - val_loss: 1.3352 - val_accuracy: 0.4727 - lr: 0.0010\n",
      "Epoch 34/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.5036 - accuracy: 0.3952\n",
      "Epoch 34: accuracy improved from 0.38726 to 0.39517, saving model to emotions.h5\n",
      "443/443 [==============================] - 176s 397ms/step - loss: 1.5036 - accuracy: 0.3952 - val_loss: 1.2648 - val_accuracy: 0.5057 - lr: 0.0010\n",
      "Epoch 35/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.5035 - accuracy: 0.3948\n",
      "Epoch 35: accuracy did not improve from 0.39517\n",
      "443/443 [==============================] - 177s 399ms/step - loss: 1.5035 - accuracy: 0.3948 - val_loss: 1.2562 - val_accuracy: 0.4943 - lr: 0.0010\n",
      "Epoch 36/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.4877 - accuracy: 0.3986\n",
      "Epoch 36: accuracy improved from 0.39517 to 0.39856, saving model to emotions.h5\n",
      "443/443 [==============================] - 176s 396ms/step - loss: 1.4877 - accuracy: 0.3986 - val_loss: 1.2705 - val_accuracy: 0.5068 - lr: 0.0010\n",
      "Epoch 37/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.4850 - accuracy: 0.4038\n",
      "Epoch 37: accuracy improved from 0.39856 to 0.40379, saving model to emotions.h5\n",
      "443/443 [==============================] - 176s 397ms/step - loss: 1.4850 - accuracy: 0.4038 - val_loss: 1.3125 - val_accuracy: 0.4801 - lr: 0.0010\n",
      "Epoch 38/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.4782 - accuracy: 0.4060\n",
      "Epoch 38: accuracy improved from 0.40379 to 0.40597, saving model to emotions.h5\n",
      "443/443 [==============================] - 178s 401ms/step - loss: 1.4782 - accuracy: 0.4060 - val_loss: 1.2923 - val_accuracy: 0.4812 - lr: 0.0010\n",
      "Epoch 39/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.4755 - accuracy: 0.4050\n",
      "Epoch 39: accuracy did not improve from 0.40597\n",
      "443/443 [==============================] - 179s 404ms/step - loss: 1.4755 - accuracy: 0.4050 - val_loss: 1.2475 - val_accuracy: 0.4932 - lr: 0.0010\n",
      "Epoch 40/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.4750 - accuracy: 0.4087\n",
      "Epoch 40: accuracy improved from 0.40597 to 0.40866, saving model to emotions.h5\n",
      "443/443 [==============================] - 179s 404ms/step - loss: 1.4750 - accuracy: 0.4087 - val_loss: 1.3420 - val_accuracy: 0.4710 - lr: 0.0010\n",
      "Epoch 41/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.4622 - accuracy: 0.4188\n",
      "Epoch 41: accuracy improved from 0.40866 to 0.41876, saving model to emotions.h5\n",
      "443/443 [==============================] - 178s 402ms/step - loss: 1.4622 - accuracy: 0.4188 - val_loss: 1.3336 - val_accuracy: 0.4773 - lr: 0.0010\n",
      "Epoch 42/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.4702 - accuracy: 0.4065\n",
      "Epoch 42: accuracy did not improve from 0.41876\n",
      "443/443 [==============================] - 178s 402ms/step - loss: 1.4702 - accuracy: 0.4065 - val_loss: 1.2316 - val_accuracy: 0.5114 - lr: 0.0010\n",
      "Epoch 43/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.4571 - accuracy: 0.4192\n",
      "Epoch 43: accuracy improved from 0.41876 to 0.41923, saving model to emotions.h5\n",
      "443/443 [==============================] - 177s 400ms/step - loss: 1.4571 - accuracy: 0.4192 - val_loss: 1.2051 - val_accuracy: 0.5284 - lr: 0.0010\n",
      "Epoch 44/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.4644 - accuracy: 0.4077\n",
      "Epoch 44: accuracy did not improve from 0.41923\n",
      "443/443 [==============================] - 179s 405ms/step - loss: 1.4644 - accuracy: 0.4077 - val_loss: 1.2612 - val_accuracy: 0.5063 - lr: 0.0010\n",
      "Epoch 45/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.4641 - accuracy: 0.4086\n",
      "Epoch 45: accuracy did not improve from 0.41923\n",
      "443/443 [==============================] - 179s 404ms/step - loss: 1.4641 - accuracy: 0.4086 - val_loss: 1.2738 - val_accuracy: 0.4892 - lr: 0.0010\n",
      "Epoch 46/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.4512 - accuracy: 0.4182\n",
      "Epoch 46: accuracy did not improve from 0.41923\n",
      "443/443 [==============================] - 178s 401ms/step - loss: 1.4512 - accuracy: 0.4182 - val_loss: 1.2325 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 47/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.4436 - accuracy: 0.4245\n",
      "Epoch 47: accuracy improved from 0.41923 to 0.42448, saving model to emotions.h5\n",
      "443/443 [==============================] - 177s 400ms/step - loss: 1.4436 - accuracy: 0.4245 - val_loss: 1.2867 - val_accuracy: 0.5023 - lr: 0.0010\n",
      "Epoch 48/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.4455 - accuracy: 0.4223\n",
      "Epoch 48: accuracy did not improve from 0.42448\n",
      "443/443 [==============================] - 176s 397ms/step - loss: 1.4455 - accuracy: 0.4223 - val_loss: 1.2578 - val_accuracy: 0.5080 - lr: 0.0010\n",
      "Epoch 49/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.4441 - accuracy: 0.4240\n",
      "Epoch 49: accuracy did not improve from 0.42448\n",
      "443/443 [==============================] - 175s 394ms/step - loss: 1.4441 - accuracy: 0.4240 - val_loss: 1.2347 - val_accuracy: 0.5159 - lr: 0.0010\n",
      "Epoch 50/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.4338 - accuracy: 0.4313\n",
      "Epoch 50: accuracy improved from 0.42448 to 0.43129, saving model to emotions.h5\n",
      "443/443 [==============================] - 179s 403ms/step - loss: 1.4338 - accuracy: 0.4313 - val_loss: 1.2559 - val_accuracy: 0.4983 - lr: 0.0010\n",
      "Epoch 51/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.4362 - accuracy: 0.4254\n",
      "Epoch 51: accuracy did not improve from 0.43129\n",
      "443/443 [==============================] - 175s 395ms/step - loss: 1.4362 - accuracy: 0.4254 - val_loss: 1.2240 - val_accuracy: 0.5182 - lr: 0.0010\n",
      "Epoch 52/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.4336 - accuracy: 0.4249\n",
      "Epoch 52: accuracy did not improve from 0.43129\n",
      "443/443 [==============================] - 190s 428ms/step - loss: 1.4336 - accuracy: 0.4249 - val_loss: 1.1830 - val_accuracy: 0.5301 - lr: 0.0010\n",
      "Epoch 53/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.4275 - accuracy: 0.4283\n",
      "Epoch 53: accuracy did not improve from 0.43129\n",
      "443/443 [==============================] - 185s 418ms/step - loss: 1.4275 - accuracy: 0.4283 - val_loss: 1.2022 - val_accuracy: 0.5233 - lr: 0.0010\n",
      "Epoch 54/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.4265 - accuracy: 0.4268\n",
      "Epoch 54: accuracy did not improve from 0.43129\n",
      "443/443 [==============================] - 184s 414ms/step - loss: 1.4265 - accuracy: 0.4268 - val_loss: 1.1865 - val_accuracy: 0.5278 - lr: 0.0010\n",
      "Epoch 55/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.4238 - accuracy: 0.4360\n",
      "Epoch 55: accuracy improved from 0.43129 to 0.43599, saving model to emotions.h5\n",
      "443/443 [==============================] - 181s 408ms/step - loss: 1.4238 - accuracy: 0.4360 - val_loss: 1.1776 - val_accuracy: 0.5352 - lr: 0.0010\n",
      "Epoch 56/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.4221 - accuracy: 0.4298\n",
      "Epoch 56: accuracy did not improve from 0.43599\n",
      "443/443 [==============================] - 179s 404ms/step - loss: 1.4221 - accuracy: 0.4298 - val_loss: 1.1769 - val_accuracy: 0.5386 - lr: 0.0010\n",
      "Epoch 57/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.4269 - accuracy: 0.4305\n",
      "Epoch 57: accuracy did not improve from 0.43599\n",
      "443/443 [==============================] - 182s 410ms/step - loss: 1.4269 - accuracy: 0.4305 - val_loss: 1.1598 - val_accuracy: 0.5528 - lr: 0.0010\n",
      "Epoch 58/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.4307 - accuracy: 0.4264\n",
      "Epoch 58: accuracy did not improve from 0.43599\n",
      "443/443 [==============================] - 186s 420ms/step - loss: 1.4307 - accuracy: 0.4264 - val_loss: 1.1917 - val_accuracy: 0.5165 - lr: 0.0010\n",
      "Epoch 59/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.4125 - accuracy: 0.4397\n",
      "Epoch 59: accuracy improved from 0.43599 to 0.43966, saving model to emotions.h5\n",
      "443/443 [==============================] - 184s 414ms/step - loss: 1.4125 - accuracy: 0.4397 - val_loss: 1.1849 - val_accuracy: 0.5301 - lr: 0.0010\n",
      "Epoch 60/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.4196 - accuracy: 0.4333\n",
      "Epoch 60: accuracy did not improve from 0.43966\n",
      "443/443 [==============================] - 182s 411ms/step - loss: 1.4196 - accuracy: 0.4333 - val_loss: 1.1974 - val_accuracy: 0.5375 - lr: 0.0010\n",
      "Epoch 61/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.4224 - accuracy: 0.4324\n",
      "Epoch 61: accuracy did not improve from 0.43966\n",
      "443/443 [==============================] - 181s 409ms/step - loss: 1.4224 - accuracy: 0.4324 - val_loss: 1.1204 - val_accuracy: 0.5472 - lr: 0.0010\n",
      "Epoch 62/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.4057 - accuracy: 0.4392\n",
      "Epoch 62: accuracy did not improve from 0.43966\n",
      "443/443 [==============================] - 213s 480ms/step - loss: 1.4057 - accuracy: 0.4392 - val_loss: 1.1776 - val_accuracy: 0.5369 - lr: 0.0010\n",
      "Epoch 63/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.4004 - accuracy: 0.4463\n",
      "Epoch 63: accuracy improved from 0.43966 to 0.44630, saving model to emotions.h5\n",
      "443/443 [==============================] - 207s 468ms/step - loss: 1.4004 - accuracy: 0.4463 - val_loss: 1.1684 - val_accuracy: 0.5403 - lr: 0.0010\n",
      "Epoch 64/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.4074 - accuracy: 0.4421\n",
      "Epoch 64: accuracy did not improve from 0.44630\n",
      "443/443 [==============================] - 204s 461ms/step - loss: 1.4074 - accuracy: 0.4421 - val_loss: 1.1723 - val_accuracy: 0.5466 - lr: 0.0010\n",
      "Epoch 65/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.4028 - accuracy: 0.4411\n",
      "Epoch 65: accuracy did not improve from 0.44630\n",
      "443/443 [==============================] - 196s 443ms/step - loss: 1.4028 - accuracy: 0.4411 - val_loss: 1.1614 - val_accuracy: 0.5335 - lr: 0.0010\n",
      "Epoch 66/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.4100 - accuracy: 0.4426\n",
      "Epoch 66: accuracy did not improve from 0.44630\n",
      "443/443 [==============================] - 189s 426ms/step - loss: 1.4100 - accuracy: 0.4426 - val_loss: 1.0935 - val_accuracy: 0.5739 - lr: 0.0010\n",
      "Epoch 67/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.4090 - accuracy: 0.4422\n",
      "Epoch 67: accuracy did not improve from 0.44630\n",
      "443/443 [==============================] - 184s 416ms/step - loss: 1.4090 - accuracy: 0.4422 - val_loss: 1.1452 - val_accuracy: 0.5562 - lr: 0.0010\n",
      "Epoch 68/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3946 - accuracy: 0.4527\n",
      "Epoch 68: accuracy improved from 0.44630 to 0.45274, saving model to emotions.h5\n",
      "443/443 [==============================] - 185s 418ms/step - loss: 1.3946 - accuracy: 0.4527 - val_loss: 1.1602 - val_accuracy: 0.5352 - lr: 0.0010\n",
      "Epoch 69/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3911 - accuracy: 0.4529\n",
      "Epoch 69: accuracy improved from 0.45274 to 0.45295, saving model to emotions.h5\n",
      "443/443 [==============================] - 184s 415ms/step - loss: 1.3911 - accuracy: 0.4529 - val_loss: 1.1952 - val_accuracy: 0.5364 - lr: 0.0010\n",
      "Epoch 70/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3905 - accuracy: 0.4489\n",
      "Epoch 70: accuracy did not improve from 0.45295\n",
      "443/443 [==============================] - 207s 468ms/step - loss: 1.3905 - accuracy: 0.4489 - val_loss: 1.1527 - val_accuracy: 0.5398 - lr: 0.0010\n",
      "Epoch 71/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3969 - accuracy: 0.4434\n",
      "Epoch 71: accuracy did not improve from 0.45295\n",
      "443/443 [==============================] - 183s 412ms/step - loss: 1.3969 - accuracy: 0.4434 - val_loss: 1.1525 - val_accuracy: 0.5688 - lr: 0.0010\n",
      "Epoch 72/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3930 - accuracy: 0.4466\n",
      "Epoch 72: accuracy did not improve from 0.45295\n",
      "443/443 [==============================] - 181s 408ms/step - loss: 1.3930 - accuracy: 0.4466 - val_loss: 1.1356 - val_accuracy: 0.5511 - lr: 0.0010\n",
      "Epoch 73/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3897 - accuracy: 0.4524\n",
      "Epoch 73: accuracy did not improve from 0.45295\n",
      "443/443 [==============================] - 181s 409ms/step - loss: 1.3897 - accuracy: 0.4524 - val_loss: 1.1391 - val_accuracy: 0.5648 - lr: 0.0010\n",
      "Epoch 74/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3862 - accuracy: 0.4561\n",
      "Epoch 74: accuracy improved from 0.45295 to 0.45612, saving model to emotions.h5\n",
      "443/443 [==============================] - 182s 411ms/step - loss: 1.3862 - accuracy: 0.4561 - val_loss: 1.1333 - val_accuracy: 0.5602 - lr: 0.0010\n",
      "Epoch 75/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3819 - accuracy: 0.4522\n",
      "Epoch 75: accuracy did not improve from 0.45612\n",
      "443/443 [==============================] - 182s 411ms/step - loss: 1.3819 - accuracy: 0.4522 - val_loss: 1.1491 - val_accuracy: 0.5614 - lr: 0.0010\n",
      "Epoch 76/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3761 - accuracy: 0.4551\n",
      "Epoch 76: accuracy did not improve from 0.45612\n",
      "443/443 [==============================] - 181s 408ms/step - loss: 1.3761 - accuracy: 0.4551 - val_loss: 1.1645 - val_accuracy: 0.5517 - lr: 0.0010\n",
      "Epoch 77/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3792 - accuracy: 0.4533\n",
      "Epoch 77: accuracy did not improve from 0.45612\n",
      "443/443 [==============================] - 182s 410ms/step - loss: 1.3792 - accuracy: 0.4533 - val_loss: 1.1092 - val_accuracy: 0.5653 - lr: 0.0010\n",
      "Epoch 78/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3873 - accuracy: 0.4504\n",
      "Epoch 78: accuracy did not improve from 0.45612\n",
      "443/443 [==============================] - 182s 410ms/step - loss: 1.3873 - accuracy: 0.4504 - val_loss: 1.1365 - val_accuracy: 0.5449 - lr: 0.0010\n",
      "Epoch 79/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3738 - accuracy: 0.4580\n",
      "Epoch 79: accuracy improved from 0.45612 to 0.45802, saving model to emotions.h5\n",
      "443/443 [==============================] - 184s 414ms/step - loss: 1.3738 - accuracy: 0.4580 - val_loss: 1.2301 - val_accuracy: 0.5324 - lr: 0.0010\n",
      "Epoch 80/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3666 - accuracy: 0.4629\n",
      "Epoch 80: accuracy improved from 0.45802 to 0.46290, saving model to emotions.h5\n",
      "443/443 [==============================] - 184s 415ms/step - loss: 1.3666 - accuracy: 0.4629 - val_loss: 1.0827 - val_accuracy: 0.5807 - lr: 0.0010\n",
      "Epoch 81/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3743 - accuracy: 0.4611\n",
      "Epoch 81: accuracy did not improve from 0.46290\n",
      "443/443 [==============================] - 185s 418ms/step - loss: 1.3743 - accuracy: 0.4611 - val_loss: 1.1103 - val_accuracy: 0.5551 - lr: 0.0010\n",
      "Epoch 82/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3699 - accuracy: 0.4525\n",
      "Epoch 82: accuracy did not improve from 0.46290\n",
      "443/443 [==============================] - 186s 419ms/step - loss: 1.3699 - accuracy: 0.4525 - val_loss: 1.1385 - val_accuracy: 0.5591 - lr: 0.0010\n",
      "Epoch 83/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3672 - accuracy: 0.4584\n",
      "Epoch 83: accuracy did not improve from 0.46290\n",
      "443/443 [==============================] - 185s 418ms/step - loss: 1.3672 - accuracy: 0.4584 - val_loss: 1.0707 - val_accuracy: 0.5864 - lr: 0.0010\n",
      "Epoch 84/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3688 - accuracy: 0.4645\n",
      "Epoch 84: accuracy improved from 0.46290 to 0.46452, saving model to emotions.h5\n",
      "443/443 [==============================] - 182s 411ms/step - loss: 1.3688 - accuracy: 0.4645 - val_loss: 1.0872 - val_accuracy: 0.5693 - lr: 0.0010\n",
      "Epoch 85/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3745 - accuracy: 0.4589\n",
      "Epoch 85: accuracy did not improve from 0.46452\n",
      "443/443 [==============================] - 182s 410ms/step - loss: 1.3745 - accuracy: 0.4589 - val_loss: 1.0795 - val_accuracy: 0.5830 - lr: 0.0010\n",
      "Epoch 86/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3738 - accuracy: 0.4567\n",
      "Epoch 86: accuracy did not improve from 0.46452\n",
      "443/443 [==============================] - 183s 414ms/step - loss: 1.3738 - accuracy: 0.4567 - val_loss: 1.1335 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 87/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3677 - accuracy: 0.4656\n",
      "Epoch 87: accuracy improved from 0.46452 to 0.46565, saving model to emotions.h5\n",
      "443/443 [==============================] - 184s 414ms/step - loss: 1.3677 - accuracy: 0.4656 - val_loss: 1.1023 - val_accuracy: 0.5591 - lr: 0.0010\n",
      "Epoch 88/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3741 - accuracy: 0.4587\n",
      "Epoch 88: accuracy did not improve from 0.46565\n",
      "443/443 [==============================] - 183s 412ms/step - loss: 1.3741 - accuracy: 0.4587 - val_loss: 1.1357 - val_accuracy: 0.5693 - lr: 0.0010\n",
      "Epoch 89/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3719 - accuracy: 0.4603\n",
      "Epoch 89: accuracy did not improve from 0.46565\n",
      "443/443 [==============================] - 184s 415ms/step - loss: 1.3719 - accuracy: 0.4603 - val_loss: 1.1062 - val_accuracy: 0.5653 - lr: 0.0010\n",
      "Epoch 90/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3693 - accuracy: 0.4548\n",
      "Epoch 90: accuracy did not improve from 0.46565\n",
      "443/443 [==============================] - 184s 416ms/step - loss: 1.3693 - accuracy: 0.4548 - val_loss: 1.0962 - val_accuracy: 0.5733 - lr: 0.0010\n",
      "Epoch 91/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3566 - accuracy: 0.4669\n",
      "Epoch 91: accuracy improved from 0.46565 to 0.46692, saving model to emotions.h5\n",
      "443/443 [==============================] - 185s 416ms/step - loss: 1.3566 - accuracy: 0.4669 - val_loss: 1.0465 - val_accuracy: 0.5966 - lr: 0.0010\n",
      "Epoch 92/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3514 - accuracy: 0.4632\n",
      "Epoch 92: accuracy did not improve from 0.46692\n",
      "443/443 [==============================] - 184s 416ms/step - loss: 1.3514 - accuracy: 0.4632 - val_loss: 1.1480 - val_accuracy: 0.5614 - lr: 0.0010\n",
      "Epoch 93/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3609 - accuracy: 0.4643\n",
      "Epoch 93: accuracy did not improve from 0.46692\n",
      "443/443 [==============================] - 184s 416ms/step - loss: 1.3609 - accuracy: 0.4643 - val_loss: 1.1080 - val_accuracy: 0.5813 - lr: 0.0010\n",
      "Epoch 94/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3588 - accuracy: 0.4636\n",
      "Epoch 94: accuracy did not improve from 0.46692\n",
      "443/443 [==============================] - 184s 415ms/step - loss: 1.3588 - accuracy: 0.4636 - val_loss: 1.0662 - val_accuracy: 0.5892 - lr: 0.0010\n",
      "Epoch 95/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3582 - accuracy: 0.4645\n",
      "Epoch 95: accuracy did not improve from 0.46692\n",
      "443/443 [==============================] - 183s 413ms/step - loss: 1.3582 - accuracy: 0.4645 - val_loss: 1.1439 - val_accuracy: 0.5483 - lr: 0.0010\n",
      "Epoch 96/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3519 - accuracy: 0.4641\n",
      "Epoch 96: accuracy did not improve from 0.46692\n",
      "443/443 [==============================] - 183s 412ms/step - loss: 1.3519 - accuracy: 0.4641 - val_loss: 1.0924 - val_accuracy: 0.5795 - lr: 0.0010\n",
      "Epoch 97/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3571 - accuracy: 0.4668\n",
      "Epoch 97: accuracy did not improve from 0.46692\n",
      "443/443 [==============================] - 183s 412ms/step - loss: 1.3571 - accuracy: 0.4668 - val_loss: 1.0615 - val_accuracy: 0.5886 - lr: 0.0010\n",
      "Epoch 98/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3538 - accuracy: 0.4649\n",
      "Epoch 98: accuracy did not improve from 0.46692\n",
      "443/443 [==============================] - 182s 411ms/step - loss: 1.3538 - accuracy: 0.4649 - val_loss: 1.0820 - val_accuracy: 0.5801 - lr: 0.0010\n",
      "Epoch 99/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3389 - accuracy: 0.4768\n",
      "Epoch 99: accuracy improved from 0.46692 to 0.47680, saving model to emotions.h5\n",
      "443/443 [==============================] - 182s 412ms/step - loss: 1.3389 - accuracy: 0.4768 - val_loss: 1.0951 - val_accuracy: 0.5813 - lr: 0.0010\n",
      "Epoch 100/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3567 - accuracy: 0.4676\n",
      "Epoch 100: accuracy did not improve from 0.47680\n",
      "443/443 [==============================] - 181s 408ms/step - loss: 1.3567 - accuracy: 0.4676 - val_loss: 1.0329 - val_accuracy: 0.6017 - lr: 0.0010\n",
      "Epoch 101/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3403 - accuracy: 0.4736\n",
      "Epoch 101: accuracy did not improve from 0.47680\n",
      "443/443 [==============================] - 182s 411ms/step - loss: 1.3403 - accuracy: 0.4736 - val_loss: 1.1029 - val_accuracy: 0.5608 - lr: 0.0010\n",
      "Epoch 102/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3465 - accuracy: 0.4719\n",
      "Epoch 102: accuracy did not improve from 0.47680\n",
      "443/443 [==============================] - 183s 412ms/step - loss: 1.3465 - accuracy: 0.4719 - val_loss: 1.0892 - val_accuracy: 0.5693 - lr: 0.0010\n",
      "Epoch 103/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3541 - accuracy: 0.4691\n",
      "Epoch 103: accuracy did not improve from 0.47680\n",
      "443/443 [==============================] - 182s 410ms/step - loss: 1.3541 - accuracy: 0.4691 - val_loss: 1.0912 - val_accuracy: 0.5688 - lr: 0.0010\n",
      "Epoch 104/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3482 - accuracy: 0.4701\n",
      "Epoch 104: accuracy did not improve from 0.47680\n",
      "443/443 [==============================] - 183s 413ms/step - loss: 1.3482 - accuracy: 0.4701 - val_loss: 1.0849 - val_accuracy: 0.5875 - lr: 0.0010\n",
      "Epoch 105/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3523 - accuracy: 0.4662\n",
      "Epoch 105: accuracy did not improve from 0.47680\n",
      "443/443 [==============================] - 182s 410ms/step - loss: 1.3523 - accuracy: 0.4662 - val_loss: 1.0679 - val_accuracy: 0.5864 - lr: 0.0010\n",
      "Epoch 106/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3473 - accuracy: 0.4708\n",
      "Epoch 106: accuracy did not improve from 0.47680\n",
      "443/443 [==============================] - 182s 410ms/step - loss: 1.3473 - accuracy: 0.4708 - val_loss: 1.1053 - val_accuracy: 0.5705 - lr: 0.0010\n",
      "Epoch 107/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3401 - accuracy: 0.4722\n",
      "Epoch 107: accuracy did not improve from 0.47680\n",
      "443/443 [==============================] - 183s 413ms/step - loss: 1.3401 - accuracy: 0.4722 - val_loss: 1.1052 - val_accuracy: 0.5693 - lr: 0.0010\n",
      "Epoch 108/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3429 - accuracy: 0.4737\n",
      "Epoch 108: accuracy did not improve from 0.47680\n",
      "443/443 [==============================] - 183s 414ms/step - loss: 1.3429 - accuracy: 0.4737 - val_loss: 1.0532 - val_accuracy: 0.6011 - lr: 0.0010\n",
      "Epoch 109/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3427 - accuracy: 0.4661\n",
      "Epoch 109: accuracy did not improve from 0.47680\n",
      "\n",
      "Epoch 109: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "443/443 [==============================] - 181s 408ms/step - loss: 1.3427 - accuracy: 0.4661 - val_loss: 1.0539 - val_accuracy: 0.5886 - lr: 0.0010\n",
      "Epoch 110/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3288 - accuracy: 0.4831\n",
      "Epoch 110: accuracy improved from 0.47680 to 0.48314, saving model to emotions.h5\n",
      "443/443 [==============================] - 181s 409ms/step - loss: 1.3288 - accuracy: 0.4831 - val_loss: 1.0394 - val_accuracy: 0.6028 - lr: 2.0000e-04\n",
      "Epoch 111/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3314 - accuracy: 0.4815\n",
      "Epoch 111: accuracy did not improve from 0.48314\n",
      "443/443 [==============================] - 182s 411ms/step - loss: 1.3314 - accuracy: 0.4815 - val_loss: 1.0811 - val_accuracy: 0.5699 - lr: 2.0000e-04\n",
      "Epoch 112/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3037 - accuracy: 0.4913\n",
      "Epoch 112: accuracy improved from 0.48314 to 0.49135, saving model to emotions.h5\n",
      "443/443 [==============================] - 192s 434ms/step - loss: 1.3037 - accuracy: 0.4913 - val_loss: 1.0542 - val_accuracy: 0.5835 - lr: 2.0000e-04\n",
      "Epoch 113/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3256 - accuracy: 0.4818\n",
      "Epoch 113: accuracy did not improve from 0.49135\n",
      "443/443 [==============================] - 181s 409ms/step - loss: 1.3256 - accuracy: 0.4818 - val_loss: 1.0644 - val_accuracy: 0.6023 - lr: 2.0000e-04\n",
      "Epoch 114/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3295 - accuracy: 0.4778\n",
      "Epoch 114: accuracy did not improve from 0.49135\n",
      "443/443 [==============================] - 179s 403ms/step - loss: 1.3295 - accuracy: 0.4778 - val_loss: 1.0571 - val_accuracy: 0.5966 - lr: 2.0000e-04\n",
      "Epoch 115/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3226 - accuracy: 0.4786\n",
      "Epoch 115: accuracy did not improve from 0.49135\n",
      "443/443 [==============================] - 180s 407ms/step - loss: 1.3226 - accuracy: 0.4786 - val_loss: 1.0189 - val_accuracy: 0.5966 - lr: 2.0000e-04\n",
      "Epoch 116/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3133 - accuracy: 0.4820\n",
      "Epoch 116: accuracy did not improve from 0.49135\n",
      "443/443 [==============================] - 184s 415ms/step - loss: 1.3133 - accuracy: 0.4820 - val_loss: 1.0339 - val_accuracy: 0.6068 - lr: 2.0000e-04\n",
      "Epoch 117/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3183 - accuracy: 0.4848\n",
      "Epoch 117: accuracy did not improve from 0.49135\n",
      "443/443 [==============================] - 183s 414ms/step - loss: 1.3183 - accuracy: 0.4848 - val_loss: 1.0273 - val_accuracy: 0.5983 - lr: 2.0000e-04\n",
      "Epoch 118/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3076 - accuracy: 0.4918\n",
      "Epoch 118: accuracy improved from 0.49135 to 0.49184, saving model to emotions.h5\n",
      "443/443 [==============================] - 181s 409ms/step - loss: 1.3076 - accuracy: 0.4918 - val_loss: 1.0632 - val_accuracy: 0.5869 - lr: 2.0000e-04\n",
      "Epoch 119/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3073 - accuracy: 0.4919\n",
      "Epoch 119: accuracy improved from 0.49184 to 0.49191, saving model to emotions.h5\n",
      "443/443 [==============================] - 180s 406ms/step - loss: 1.3073 - accuracy: 0.4919 - val_loss: 1.0568 - val_accuracy: 0.5886 - lr: 2.0000e-04\n",
      "Epoch 120/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3054 - accuracy: 0.4917\n",
      "Epoch 120: accuracy did not improve from 0.49191\n",
      "443/443 [==============================] - 179s 405ms/step - loss: 1.3054 - accuracy: 0.4917 - val_loss: 1.0126 - val_accuracy: 0.6085 - lr: 2.0000e-04\n",
      "Epoch 121/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3112 - accuracy: 0.4875\n",
      "Epoch 121: accuracy did not improve from 0.49191\n",
      "443/443 [==============================] - 176s 398ms/step - loss: 1.3112 - accuracy: 0.4875 - val_loss: 1.0248 - val_accuracy: 0.5903 - lr: 2.0000e-04\n",
      "Epoch 122/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3047 - accuracy: 0.4894\n",
      "Epoch 122: accuracy did not improve from 0.49191\n",
      "443/443 [==============================] - 175s 395ms/step - loss: 1.3047 - accuracy: 0.4894 - val_loss: 1.0408 - val_accuracy: 0.5977 - lr: 2.0000e-04\n",
      "Epoch 123/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3147 - accuracy: 0.4879\n",
      "Epoch 123: accuracy did not improve from 0.49191\n",
      "443/443 [==============================] - 175s 396ms/step - loss: 1.3147 - accuracy: 0.4879 - val_loss: 1.0945 - val_accuracy: 0.5688 - lr: 2.0000e-04\n",
      "Epoch 124/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3119 - accuracy: 0.4931\n",
      "Epoch 124: accuracy improved from 0.49191 to 0.49311, saving model to emotions.h5\n",
      "443/443 [==============================] - 175s 396ms/step - loss: 1.3119 - accuracy: 0.4931 - val_loss: 1.0469 - val_accuracy: 0.5852 - lr: 2.0000e-04\n",
      "Epoch 125/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.2975 - accuracy: 0.4923\n",
      "Epoch 125: accuracy did not improve from 0.49311\n",
      "443/443 [==============================] - 175s 396ms/step - loss: 1.2975 - accuracy: 0.4923 - val_loss: 1.0311 - val_accuracy: 0.6062 - lr: 2.0000e-04\n",
      "Epoch 126/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3042 - accuracy: 0.4949\n",
      "Epoch 126: accuracy improved from 0.49311 to 0.49492, saving model to emotions.h5\n",
      "443/443 [==============================] - 175s 396ms/step - loss: 1.3042 - accuracy: 0.4949 - val_loss: 1.0360 - val_accuracy: 0.5949 - lr: 2.0000e-04\n",
      "Epoch 127/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.2948 - accuracy: 0.4906\n",
      "Epoch 127: accuracy did not improve from 0.49492\n",
      "443/443 [==============================] - 175s 396ms/step - loss: 1.2948 - accuracy: 0.4906 - val_loss: 1.0724 - val_accuracy: 0.5858 - lr: 2.0000e-04\n",
      "Epoch 128/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3065 - accuracy: 0.4895\n",
      "Epoch 128: accuracy did not improve from 0.49492\n",
      "443/443 [==============================] - 182s 411ms/step - loss: 1.3065 - accuracy: 0.4895 - val_loss: 1.0776 - val_accuracy: 0.5773 - lr: 2.0000e-04\n",
      "Epoch 129/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3066 - accuracy: 0.4883\n",
      "Epoch 129: accuracy did not improve from 0.49492\n",
      "443/443 [==============================] - 167s 377ms/step - loss: 1.3066 - accuracy: 0.4883 - val_loss: 1.0370 - val_accuracy: 0.5938 - lr: 2.0000e-04\n",
      "Epoch 130/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3055 - accuracy: 0.4879\n",
      "Epoch 130: accuracy did not improve from 0.49492\n",
      "443/443 [==============================] - 166s 375ms/step - loss: 1.3055 - accuracy: 0.4879 - val_loss: 1.0314 - val_accuracy: 0.6097 - lr: 2.0000e-04\n",
      "Epoch 131/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3082 - accuracy: 0.4870\n",
      "Epoch 131: accuracy did not improve from 0.49492\n",
      "443/443 [==============================] - 166s 374ms/step - loss: 1.3082 - accuracy: 0.4870 - val_loss: 1.0261 - val_accuracy: 0.6136 - lr: 2.0000e-04\n",
      "Epoch 132/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.2952 - accuracy: 0.4940\n",
      "Epoch 132: accuracy did not improve from 0.49492\n",
      "443/443 [==============================] - 166s 374ms/step - loss: 1.2952 - accuracy: 0.4940 - val_loss: 1.0210 - val_accuracy: 0.6000 - lr: 2.0000e-04\n",
      "Epoch 133/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.2942 - accuracy: 0.4966\n",
      "Epoch 133: accuracy improved from 0.49492 to 0.49661, saving model to emotions.h5\n",
      "443/443 [==============================] - 166s 376ms/step - loss: 1.2942 - accuracy: 0.4966 - val_loss: 1.0746 - val_accuracy: 0.5926 - lr: 2.0000e-04\n",
      "Epoch 134/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3021 - accuracy: 0.4929\n",
      "Epoch 134: accuracy did not improve from 0.49661\n",
      "443/443 [==============================] - 166s 374ms/step - loss: 1.3021 - accuracy: 0.4929 - val_loss: 1.0751 - val_accuracy: 0.5869 - lr: 2.0000e-04\n",
      "Epoch 135/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.2972 - accuracy: 0.4984\n",
      "Epoch 135: accuracy improved from 0.49661 to 0.49838, saving model to emotions.h5\n",
      "443/443 [==============================] - 167s 376ms/step - loss: 1.2972 - accuracy: 0.4984 - val_loss: 0.9914 - val_accuracy: 0.6034 - lr: 2.0000e-04\n",
      "Epoch 136/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3012 - accuracy: 0.4898\n",
      "Epoch 136: accuracy did not improve from 0.49838\n",
      "443/443 [==============================] - 166s 375ms/step - loss: 1.3012 - accuracy: 0.4898 - val_loss: 1.0358 - val_accuracy: 0.5920 - lr: 2.0000e-04\n",
      "Epoch 137/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.2934 - accuracy: 0.4925\n",
      "Epoch 137: accuracy did not improve from 0.49838\n",
      "443/443 [==============================] - 169s 382ms/step - loss: 1.2934 - accuracy: 0.4925 - val_loss: 1.0558 - val_accuracy: 0.5977 - lr: 2.0000e-04\n",
      "Epoch 138/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.2983 - accuracy: 0.4919\n",
      "Epoch 138: accuracy did not improve from 0.49838\n",
      "443/443 [==============================] - 166s 374ms/step - loss: 1.2983 - accuracy: 0.4919 - val_loss: 1.0078 - val_accuracy: 0.6125 - lr: 2.0000e-04\n",
      "Epoch 139/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.2956 - accuracy: 0.4934\n",
      "Epoch 139: accuracy did not improve from 0.49838\n",
      "443/443 [==============================] - 166s 375ms/step - loss: 1.2956 - accuracy: 0.4934 - val_loss: 0.9915 - val_accuracy: 0.6187 - lr: 2.0000e-04\n",
      "Epoch 140/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3012 - accuracy: 0.4918\n",
      "Epoch 140: accuracy did not improve from 0.49838\n",
      "443/443 [==============================] - 166s 375ms/step - loss: 1.3012 - accuracy: 0.4918 - val_loss: 1.0564 - val_accuracy: 0.5892 - lr: 2.0000e-04\n",
      "Epoch 141/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3007 - accuracy: 0.4934\n",
      "Epoch 141: accuracy did not improve from 0.49838\n",
      "443/443 [==============================] - 166s 374ms/step - loss: 1.3007 - accuracy: 0.4934 - val_loss: 1.0627 - val_accuracy: 0.5909 - lr: 2.0000e-04\n",
      "Epoch 142/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.2963 - accuracy: 0.4957\n",
      "Epoch 142: accuracy did not improve from 0.49838\n",
      "443/443 [==============================] - 166s 374ms/step - loss: 1.2963 - accuracy: 0.4957 - val_loss: 1.0193 - val_accuracy: 0.6114 - lr: 2.0000e-04\n",
      "Epoch 143/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.2968 - accuracy: 0.4933\n",
      "Epoch 143: accuracy did not improve from 0.49838\n",
      "443/443 [==============================] - 166s 374ms/step - loss: 1.2968 - accuracy: 0.4933 - val_loss: 1.0069 - val_accuracy: 0.6261 - lr: 2.0000e-04\n",
      "Epoch 144/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.2979 - accuracy: 0.4888\n",
      "Epoch 144: accuracy did not improve from 0.49838\n",
      "443/443 [==============================] - 167s 377ms/step - loss: 1.2979 - accuracy: 0.4888 - val_loss: 1.0547 - val_accuracy: 0.5938 - lr: 2.0000e-04\n",
      "Epoch 145/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.3010 - accuracy: 0.4902\n",
      "Epoch 145: accuracy did not improve from 0.49838\n",
      "\n",
      "Epoch 145: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "443/443 [==============================] - 166s 375ms/step - loss: 1.3010 - accuracy: 0.4902 - val_loss: 1.0225 - val_accuracy: 0.6091 - lr: 2.0000e-04\n",
      "Epoch 146/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.2937 - accuracy: 0.4969\n",
      "Epoch 146: accuracy did not improve from 0.49838\n",
      "443/443 [==============================] - 166s 374ms/step - loss: 1.2937 - accuracy: 0.4969 - val_loss: 1.0133 - val_accuracy: 0.6125 - lr: 1.0000e-04\n",
      "Epoch 147/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.2988 - accuracy: 0.4915\n",
      "Epoch 147: accuracy did not improve from 0.49838\n",
      "443/443 [==============================] - 167s 378ms/step - loss: 1.2988 - accuracy: 0.4915 - val_loss: 1.0332 - val_accuracy: 0.6085 - lr: 1.0000e-04\n",
      "Epoch 148/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.2984 - accuracy: 0.4934\n",
      "Epoch 148: accuracy did not improve from 0.49838\n",
      "443/443 [==============================] - 166s 374ms/step - loss: 1.2984 - accuracy: 0.4934 - val_loss: 1.0410 - val_accuracy: 0.5972 - lr: 1.0000e-04\n",
      "Epoch 149/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.2981 - accuracy: 0.4945\n",
      "Epoch 149: accuracy did not improve from 0.49838\n",
      "443/443 [==============================] - 166s 374ms/step - loss: 1.2981 - accuracy: 0.4945 - val_loss: 1.0426 - val_accuracy: 0.6023 - lr: 1.0000e-04\n",
      "Epoch 150/150\n",
      "443/443 [==============================] - ETA: 0s - loss: 1.2885 - accuracy: 0.4990\n",
      "Epoch 150: accuracy improved from 0.49838 to 0.49901, saving model to emotions.h5\n",
      "443/443 [==============================] - 168s 380ms/step - loss: 1.2885 - accuracy: 0.4990 - val_loss: 1.0286 - val_accuracy: 0.5841 - lr: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e5c0407250>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_samples = 28353\n",
    "validation_samples = 3534\n",
    "epochs = 150\n",
    "batch_size = 64\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = Adam(lr = 0.001),\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "model.fit(train_generator,\n",
    "          steps_per_epoch = train_samples//batch_size,\n",
    "          epochs = epochs,\n",
    "          callbacks = [checkpoint, reduce, tensorboard_Visualization],\n",
    "          validation_data = validation_generator,\n",
    "          validation_steps = validation_samples//batch_size,\n",
    "          shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
